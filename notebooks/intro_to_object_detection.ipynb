{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TABLE OF CONTENT**\n",
    "- [What is an image?](#What-is-an-image?)\n",
    "- [Introduction to Computer Vision](#Introduction-to-Computer-Vision)\n",
    "- [The Viola-Jones algorithm](#The-Viola-Jones-algorithm)\n",
    "- [Intro to OpenCV](#Intro-to-OpenCV)\n",
    "--- \n",
    "![image](https://blog-c7ff.kxcdn.com/blog/wp-content/uploads/2018/08/shutterstock_668209624-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an image?\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For half of century, we've been trying to give computers the ability to see but to hear is not the same as listening the same way that to take pictures is not the same as seeing. In order to udnerstand how computers see, we must first understand how they represent images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How computers see is very different to how us human perceive things. This perception of color derives from the stimulation of cone cells in the human eye while the process of perception is a very debated matter. \n",
    "\n",
    "Ever since the invention of digital imagery, computers have been able to store images, but only recently have they begun to truly see. When you take a picture with a camera. The captured images are digitized and stored as a computer file. The light intensity is essentially transformed into a matrix of pixels.\n",
    "\n",
    "A pixel is essentially a very tiny colored dot on your computer, usually made up of 3 colors (usually RGB) each assigned a particular intensity. The tri-color nature of pixels derives from the three primary colors, from which all colors visible in the human spectrum can be generated\n",
    "\n",
    "![img](https://web.stanford.edu/class/cs101/image-diagram2.png)\n",
    "\n",
    "Computer vision is essentially the field of AI concerned with deriving meaningful interpretation from pictures and videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've probably used computer vision on several occasions in some shape or form, with softwares like photoshop or your phone's picture editor. These are essentially mathematical operations executed on the original picture.\n",
    "\n",
    "![img](https://blogsimages.adobe.com/jkost/files/2013/09/39filters.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But computer vision has many more applications like image retrieval, surveilance, self-driving capabilties, etc. \n",
    "\n",
    "These applications require the use of object detection. Object detection revolves around the idea of using algorithms to detect and classify instances of real-world objects present in a picture or video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic concept is that each object class has its own special features that helps in classifying the class (i.e. all circles are round, the eiffel tower is always the same shape, etc.)\n",
    "\n",
    "Object class detection uses these special features. For example, when looking for circles, objects that are at a particular distance from a point (i.e. the center) are sought. Similarly, when looking for squares, objects that are perpendicular at corners and have equal side lengths are needed. A similar approach is used for face identification where eyes, nose, and lips can be found and features like skin color and distance between eyes can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Viola-Jones algorithm\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Violaâ€“Jones object detection framework is the first object detection framework to provide competitive object detection rates in real-time proposed in 2001 by Paul Viola and Michael Jones. The paper can be downloaded by clicking [here](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haar-like features:**\n",
    "\n",
    "In order to understand how the algorithm works, we must understand what is trying to identify. In  this case, we use haar-like features, which are digital image features used in object recognition.\n",
    "\n",
    "Haar-like features essentially come in three different shapes:\n",
    "\n",
    "![img](https://docs.opencv.org/3.4.3/haar_features.jpg)\n",
    "\n",
    "The basic idea is that we can use these haars-like feature to represent most facial features, template-matching them to unique human traits such as the nose, eyebrows, mouth etc. When turning our image to gray-scale, edges and lines can be defined by the difference in intensity between adjacent pixels (i.e. a line of darker pixels parallel to a line of whiter pixels most likely represent an edge).\n",
    "\n",
    "![img](https://cdn-images-1.medium.com/max/1600/1*pVXDRb6aiq-VtfnOu17Q8w.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viola-Jones object detection framework:**\n",
    "\n",
    "In order to get the intuition behing the algorithm, one can imagine a moving window that slides over the grayed image, aiming to identify haar-like features. \n",
    "\n",
    "![gif](https://www.pyimagesearch.com/wp-content/uploads/2014/10/sliding_window_example.gif)\n",
    "\n",
    "\n",
    "\n",
    "As one can imagine, regions like the nose, eyebrows and the mouth are a perfect fit for haar-like features and can serve as very powerful predictors. When a feature is recognized, a positive indication is fedback to the model and when enough of positive classes are detected (i.e. two eyes + a mouth), the algorithm classify the area of interest as a face/eye/body (or whatever we are trying to identify).\n",
    "\n",
    "![img](./haars_detection.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to OpenCV\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://jayrambhia.files.wordpress.com/2012/06/opencv_hor_900_1.jpg)\n",
    "\n",
    "\n",
    "Now that we know the basic theory behind face detection, let's move onto the implementation.\n",
    "\n",
    "For this exercise we use OpenCV, an open-source library of programming functions mainly aimed at real-time computer vision. \n",
    "Luckily for us, OpenCV comes with pre-trained Haar-cascading algorithms (face, eyes, smiles, etc.). This means that all we have to do is load the algorithm and apply it onto our processed images. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move onto the face-detection exercise, open the file titled face_detection_template.ipynb or click [here](./face_detection_template.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
