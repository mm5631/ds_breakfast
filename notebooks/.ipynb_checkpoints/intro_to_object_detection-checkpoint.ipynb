{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TABLE OF CONTENT**\n",
    "- [What is an image?](#What-is-an-image?)\n",
    "- [Introduction to Computer Vision](#Introduction-to-Computer-Vision)\n",
    "- [The Viola-Jones algorithm](#The-Viola-Jones-algorithm)\n",
    "- [Intro to OpenCV](#Intro-to-OpenCV)\n",
    "--- \n",
    "![image](https://blog-c7ff.kxcdn.com/blog/wp-content/uploads/2018/08/shutterstock_668209624-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an image?\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For half of century, we've been trying to give computers the ability to see.  In order to understand how computers see, we must first understand how they represent images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How computers see is very different to how us human perceive things. For us, the perception of color originates from light refracted by objects and the stimulation of cone cells in the eye. Computers vision, on the other hand, is only possible through digital imagery.\n",
    "\n",
    "To hear is not the same as to listen and to take pictures is not the same as to see. Ever since the invention of digital imagery, computers have been able to store images, but only recently have they advances in technology allowed computers to \"see\". \n",
    "\n",
    "When a photograph or video is taken, the captured images are digitized and stored as a computer file. Images are materialized through the use of pixels and colors are defined by pixel intensity.\n",
    "\n",
    "A pixel is essentially a very tiny colored dot on your computer, composed of 3 colors (usually RGB) each assigned a particular intensity. The tri-color nature of pixels derives from the three primary colors, from which all colors visible domain can be generated. A colored image is essentially three color layers superposed.\n",
    "\n",
    "_Three dimensional representation of an image:_\n",
    "![img](https://blog.xrds.acm.org/wp-content/uploads/2016/06/Figure1.png)\n",
    "\n",
    "_One dimensional representation of an image:_\n",
    "![img](https://web.stanford.edu/class/cs101/image-diagram2.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Computer vision is essentially the field of AI concerned with teaching machines to interpret pictures and videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've probably used computer vision on several occasions in some shape or form, with softwares like photoshop or your phone's picture editor. These are essentially mathematical operations executed on the original picture.\n",
    "\n",
    "_Photoshop filters examples:_\n",
    "![img](https://blogsimages.adobe.com/jkost/files/2013/09/39filters.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advances in computational power over the last 20 years has led to many more applications like surveillance, self-driving capabilties, and animojis. \n",
    "\n",
    "Most of these applications require the use of object detection in some shape or form. Object detection revolves around the idea of using algorithms to detect and classify instances of real-world objects present in a picture or video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic concept is that each object class has its own special features that helps in classifying the class (i.e. all circles are round, the eiffel tower is always the same shape, humans usally have two legs and two arms, etc.)\n",
    "\n",
    "Object class detection uses these special features. For example, when looking for circles, objects that are at a particular distance from a point (i.e. the center) are sought. Similarly, when looking for squares, objects that are perpendicular at corners come to mind. A similar approach is used for face identification where eyes, nose, and lips can be found and features like skin color and distance between eyes can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Viola-Jones algorithm\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Violaâ€“Jones object detection framework is the first object detection framework to provide competitive object detection rates in real-time proposed in 2001 by Paul Viola and Michael Jones. The paper can be downloaded by clicking [here](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gray scaling:**\n",
    "\n",
    "A very simple trick applied in object detection is to use a gray-scaled version of the image. This reduces the dimensionality of the image. Instead of being 3 dimensional (across the three color channels), each pixel is assigned a single value on the gray scale. This very simple trick makes object detection much easier!\n",
    "\n",
    "![img](http://ai.stanford.edu/~syyeung/cvweb/Pictures1/imagematrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haar-like features:**\n",
    "\n",
    "In order to understand how the algorithm works, we must understand what is trying to identify. In  this case, we use haar-like features, which are digital image features used in object recognition.\n",
    "\n",
    "Haar-like features essentially come in three different shapes:\n",
    "\n",
    "![img](https://docs.opencv.org/3.4.3/haar_features.jpg)\n",
    "\n",
    "The basic idea is that we can use these haars-like feature to represent most facial features, template-matching them to unique human traits such as the nose, eyebrows, mouth etc. When turning our image to gray-scale, edges and lines can be defined by the difference in intensity between adjacent pixels (i.e. a line of darker pixels parallel to a line of whiter pixels most likely represent an edge).\n",
    "\n",
    "![img](https://cdn-images-1.medium.com/max/1600/1*pVXDRb6aiq-VtfnOu17Q8w.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viola-Jones object detection framework:**\n",
    "\n",
    "In order to get the intuition behing the algorithm, one can imagine a moving window that slides over the grayed image, aiming to identify haar-like features. \n",
    "\n",
    "![gif](https://www.pyimagesearch.com/wp-content/uploads/2014/10/sliding_window_example.gif)\n",
    "\n",
    "\n",
    "\n",
    "As one can imagine, regions like the nose, eyebrows and the mouth are a perfect fit for haar-like features and can serve as very powerful predictors. When a feature is recognized, a positive indication is fedback to the model and when enough of positive classes are detected (i.e. two eyes + a mouth), the algorithm classify the area of interest as a face/eye/body (or whatever we are trying to identify).\n",
    "\n",
    "![img](./haars_detection.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to OpenCV\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://jayrambhia.files.wordpress.com/2012/06/opencv_hor_900_1.jpg)\n",
    "\n",
    "\n",
    "Now that we know the basic theory behind face detection, let's move onto the implementation.\n",
    "\n",
    "For this exercise we use OpenCV, an open-source library of programming functions mainly aimed at real-time computer vision. \n",
    "Luckily for us, OpenCV comes with models implementing the viola-jones alogirthm. This means that all we have to do is load the algorithm and apply it onto our processed images. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move onto the face-detection exercise, open the file titled face_detection_template.ipynb or click [here](./face_detection_template.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
