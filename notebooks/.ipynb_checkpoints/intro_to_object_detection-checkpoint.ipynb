{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TABLE OF CONTENT**\n",
    "- [What is an image?](#What-is-an-image?)\n",
    "- [Introduction to Computer Vision](#Introduction-to-Computer-Vision)\n",
    "- [The Viola-Jones algorithm](#The-Viola-Jones-algorithm)\n",
    "- [Intro to OpenCV](#Intro-to-OpenCV)\n",
    "--- \n",
    "![image](https://blog-c7ff.kxcdn.com/blog/wp-content/uploads/2018/08/shutterstock_668209624-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an image?\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For half of century, we've been trying to give computers the ability to see. \n",
    "To hear is not the same as listening and to take pictures is not the same as seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How computers see is very different to how us human perceive things. This perception of color derives from the stimulation of cone cells in the human eye while the process of perception is a very debated matter. \n",
    "\n",
    "Ever since the invention of digital imagery, computers have been able to store images, but only recently have they begun to truly see. When you take a picture with a camera. The captured images are digitized and stored as a computer file. The light intensity is essentially transformed into a matrix of pixels.\n",
    "\n",
    "Let's say your camera offers 12 Mega pixel, it means that each picture is represented by 12 million pixels, each assigned a color from a combination of primary red, green, blue. This is called RGB color model\n",
    "\n",
    "Each color will take a value between 0 and 255 (low to high intensity).\n",
    "\n",
    "![img](https://web.stanford.edu/class/cs101/image-diagram2.png)\n",
    "\n",
    "Computer vision is essentially the field of manipulating those matrices to derive meaningful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Vision\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've probably used computer vision on several occasions, with softwares like photoshop or your phone's picture editor. These are essentially mathematical operations executed on the original picture.\n",
    "\n",
    "![img](https://blogsimages.adobe.com/jkost/files/2013/09/39filters.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But computer vision has many more applications like image retrieval, surveilance, self-driving capabilties, etc. \n",
    "\n",
    "These applications require the use of object detection. Object detection revolves around the idea of using algorithms to detect and classify instances of real-world objects present in a picture or video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic concept is that each object class has its own special features that helps in classifying the class (i.e. all circles are round, the eiffel tower is always the same shape, etc.)\n",
    "\n",
    "Object class detection uses these special features. For example, when looking for circles, objects that are at a particular distance from a point (i.e. the center) are sought. Similarly, when looking for squares, objects that are perpendicular at corners and have equal side lengths are needed. A similar approach is used for face identification where eyes, nose, and lips can be found and features like skin color and distance between eyes can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Viola-Jones algorithm\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Violaâ€“Jones object detection framework is the first object detection framework to provide competitive object detection rates in real-time proposed in 2001 by Paul Viola and Michael Jones. The paper can be downloaded by clicking [here](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haar-like features:**\n",
    "\n",
    "In order to understand how the algorithm works, we must understand what is trying to identify. In  this case, we use haar-like features. \n",
    "\n",
    "A Haar-like feature considers adjacent rectangular regions at a specific location in a detection window, sums up the pixel intensities in each region and calculates the difference between these sums. This difference is then used to categorize subsections of an image. For example, let us say we have an image database with human faces. It is a common observation that among all faces the region of the eyes is darker than the region of the cheeks. Therefore a common Haar feature for face detection is a set of two adjacent rectangles that lie above the eye and the cheek region. \n",
    "\n",
    "![img](https://i.stack.imgur.com/mVBld.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viola-Jones object detection framework:**\n",
    "\n",
    "\n",
    "![gif](https://www.pyimagesearch.com/wp-content/uploads/2014/10/sliding_window_example.gif)\n",
    "\n",
    "In order to get the intuition behing the algorithm, one can picture a moving window that slides over the image, aiming to identify haar-like features. When a feature is recognized, a positive indication is fedback to the model and when enough of positive classes are detected (i.e. two eyes + a mouth), the algorithm classify the area of interest as a face/eye/body (or whatever we are trying to identify).\n",
    "\n",
    "\n",
    "\n",
    "As one can imagine, regions like the nose, eyebrows and the mouth are a perfect fit for haar-like features and can serve as very powerful predictors.\n",
    "\n",
    "![img](https://docs.opencv.org/3.4.3/haar.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to OpenCV\n",
    "[Return to top](#Intro-to-Object-Detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://jayrambhia.files.wordpress.com/2012/06/opencv_hor_900_1.jpg)\n",
    "\n",
    "\n",
    "Now that we know the basic theory behind face detection, let's move onto the implementation.\n",
    "\n",
    "For this exercise we use OpenCV, an open-source library of programming functions mainly aimed at real-time computer vision. \n",
    "Luckily for us, OpenCV comes with pre-trained Haar-cascading algorithms (face, eyes, smiles, etc.). This means that all we have to do is load the algorithm and apply it onto our processed images. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To move onto the face-detection exercise, open the file titled face_detection_template.ipynb or click [here](./face_detection_template.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
